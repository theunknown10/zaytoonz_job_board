import { generateObject, generateText, streamObject } from 'ai';
import { LlamaJsonSchemaGrammar, LlamaContext, LlamaChatSession, } from 'node-llama-cpp';
import { zodToJsonSchema } from 'zod-to-json-schema';
const defaultPrompt = 'You are a sophisticated web scraper. Extract the contents of the webpage';
const defaultCodePrompt = `Provide a scraping function in JavaScript that extracts and formats data according to a schema from the current page.
The function must be IIFE. No comments or imports. The code you generate will be executed straight away, you shouldn't output anything besides runnable code.`;
function prepareAISDKPage(page) {
    if (page.format === 'image') {
        return [
            {
                type: 'image',
                image: page.content,
            },
        ];
    }
    return [{ type: 'text', text: page.content }];
}
export async function generateAISDKCompletions(model, page, schema, options) {
    const content = prepareAISDKPage(page);
    const result = await generateObject({
        model,
        messages: [
            { role: 'system', content: options?.prompt || defaultPrompt },
            { role: 'user', content },
        ],
        schema,
        temperature: options?.temperature,
        maxTokens: options?.maxTokens,
        topP: options?.topP,
        mode: options?.mode,
    });
    return {
        data: result.object,
        url: page.url,
    };
}
export async function streamAISDKCompletions(model, page, schema, options) {
    const content = prepareAISDKPage(page);
    const { partialObjectStream } = await streamObject({
        model,
        messages: [
            { role: 'system', content: options?.prompt || defaultPrompt },
            { role: 'user', content },
        ],
        schema,
        temperature: options?.temperature,
        maxTokens: options?.maxTokens,
        topP: options?.topP,
    });
    return {
        stream: partialObjectStream,
        url: page.url,
    };
}
export async function generateAISDKCode(model, page, schema, options) {
    const generatedSchema = zodToJsonSchema(schema);
    const result = await generateText({
        model,
        messages: [
            { role: 'system', content: options?.prompt || defaultCodePrompt },
            {
                role: 'user',
                content: `Website: ${page.url}
        Schema: ${JSON.stringify(generatedSchema)}
        Content: ${page.content}`,
            },
        ],
        temperature: options?.temperature,
        maxTokens: options?.maxTokens,
        topP: options?.topP,
    });
    return {
        code: result.text,
        url: page.url,
    };
}
export async function generateLlamaCompletions(model, page, schema, options) {
    const generatedSchema = zodToJsonSchema(schema);
    const grammar = new LlamaJsonSchemaGrammar(generatedSchema); // any, because it has type inference going wild
    const context = new LlamaContext({ model });
    const session = new LlamaChatSession({ context });
    const pagePrompt = `${options?.prompt || defaultPrompt}\n${page.content}`;
    const result = await session.prompt(pagePrompt, {
        grammar,
        temperature: options?.temperature,
        maxTokens: options?.maxTokens,
        topP: options?.topP,
    });
    const parsed = grammar.parse(result);
    return {
        data: parsed,
        url: page.url,
    };
}
